{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e27e0f6",
   "metadata": {},
   "source": [
    "# SIECI NEURONOWE ‚Äì ƒáwiczenie 2\n",
    "W drugim ƒáwiczeniu zajmiemy siƒô uczeniem maszynowym. Wykorzystamy regresjƒô logistycznƒÖ ‚Äì metodƒô statystycznƒÖ kt√≥ra mo≈ºna uznaƒá za formƒô najprostszej (jednowarstwowej) sieci neuronowej. Model bƒôdziemy wykorzystywaƒá do klasyfikacji, czyli chcemy, aby aproksymowa≈Ç prawdopodobie≈Ñstwo przynale≈ºno≈õci pr√≥bki opisanej wektorem x do w≈Ça≈õciwej klasy. Do tego celu mo≈ºemy wykorzystaƒá zbi√≥r przyk≈Çad√≥w uczƒÖcych w postaci par wej≈õcie-klasa. Mo≈ºemy zdefiniowaƒá wyj≈õcie jako:\n",
    "\n",
    "ùëù(ùë•) = ùúé(ùëäùë• + ùëè)\n",
    "\n",
    "Gdzie x to wektor wej≈õciowy, W i b to parametry modelu natomiast funkcja sigma to:\n",
    "\n",
    "œÉ(n) = 1 / (1 + ùëí‚àíùëõ)\n",
    "\n",
    "Jest to wygodna funkcja dajƒÖca wyniki przedziale [0,1] dla ka≈ºdego rzeczywistego n, przy okazji rosnƒÖca i r√≥≈ºniczkowalna.\n",
    "\n",
    "Aby wyuczyƒá model w jakikolwiek spos√≥b, potrzebujemy zdefiniowanego zadania optymalizacji, a do tego potrzebujemy funkcji kosztu kt√≥rƒÖ bƒôdziemy minimalizowaƒá.\n",
    "\n",
    "Korzystamy z entropii krzy≈ºowej, dla przyk≈Çadu (x,y) w klasyfikacji binarnej:\n",
    "\n",
    "ùêø = ‚àíùë¶ ln ùëù(ùë•) ‚àí (1 ‚àí ùë¶) ln(1 ‚àí ùëù(ùë•))\n",
    "\n",
    "(y bƒôdzie zawsze zerem lub jedynkƒÖ, czyli tylko jeden ze sk≈Çadnik√≥w bƒôdzie niezerowy. Warto≈õƒá sumujemy po wszystkich przyk≈Çadach w zbiorze danych, suma bƒôdzie pominiƒôta w wzorach.)\n",
    "\n",
    "ZaletƒÖ takiego kosztu jest fakt, ≈ºe jej pochodna po wagach modelu jest bardzo prosta:\n",
    "\n",
    "ùúïùêø / ùúïùë§ùëñ = ‚àí(ùë¶ ‚àí ùëù(ùë•))ùë•ùëñ\n",
    "\n",
    "Optymalizacja modelu bƒôdzie polega≈Ça na wykonywaniu niewielkich krok√≥w w kierunku wyznaczonym przez gradient ‚Äì pochodne czƒÖstkowe po wszystkich wagach ‚Äì w pƒôtli uczenia, a≈º model osiƒÖgnie zbie≈ºno≈õƒá. Innymi s≈Çowy, aktualizujemy wagi wed≈Çug:\n",
    "\n",
    "ùë§ùëñ' = ùë§ùëñ ‚àí ùõº * ùúïùêø / ùúïùë§ùëñ\n",
    "\n",
    "Gdzie alfa to pewien wsp√≥≈Çczynnik uczenia, hiperparametr kt√≥ry musimy ustawiƒá z g√≥ry.\n",
    "\n",
    "Zadaniem na zajƒôcia 2 jest implementacja dzia≈ÇajƒÖcego na zbiorze heart disease modelu klasyfikacji, przy czym:\n",
    "\n",
    "- Zbie≈ºno≈õƒá modelu mo≈ºna zdefiniowaƒá przez wystarczajƒÖco ma≈ÇƒÖ zmianƒô funkcji kosztu w danej iteracji i pewnƒÖ maksymalnƒÖ liczbƒô iteracji\n",
    "- Model mo≈ºe uczyƒá siƒô wyliczajƒÖc sumarycznƒÖ pochodnƒÖ z funkcji kosztu po ca≈Çym zbiorze, po jednym przyk≈Çadzie lub po paczce przyk≈Çad√≥w w iteracji. Dla sieci neuronowej w nastƒôpnym zadaniu bƒôdzie ju≈º wymagany tryb paczkowania, wiƒôc warto przeƒáwiczyƒá operacje na ca≈Çych macierzach a nie tylko pojedynczych wektorach danych\n",
    "- Uczenie siƒô modelu powinno byƒá weryfikowalne metrykƒÖ (np. accuracy, fscore,\n",
    "precision ‚Äì mo≈ºna korzystaƒá z bibliotek)\n",
    "- Weryfikacja powinna uwzglƒôdniƒá podzia≈Ç na dane uczƒÖce i testowe\n",
    "\n",
    "ƒÜwiczenie oceniane jest w skali 0-10 pkt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8485c6",
   "metadata": {},
   "source": [
    "## ≈Åadowanie Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1da34314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "data = pd.read_csv('../heart-disease/processed.cleveland.data', header=None, names=column_names, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4958ae",
   "metadata": {},
   "source": [
    "## Normalizacja cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6a9563c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba brak√≥w przed dropem:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "num         0\n",
      "dtype: int64\n",
      "\n",
      "Liczba brak√≥w po dropie:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "num         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = data.replace('?', np.nan)\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(\"Liczba brak√≥w przed dropem:\")\n",
    "print(data.isna().sum())\n",
    "data = data.dropna()\n",
    "print(\"\\nLiczba brak√≥w po dropie:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "data['num'] = (data['num'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b27298",
   "metadata": {},
   "source": [
    "## Podzia≈Ç na zbi√≥r testowy i uczƒÖcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a15a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('num', axis=1)\n",
    "y = data['num']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15b9be",
   "metadata": {},
   "source": [
    "## Inicjacja wag i funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d449cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-15\n",
    "\n",
    "# Inicjacja listy wag, W, b\n",
    "n_features = X_train.shape[1]\n",
    "W = np.zeros(n_features)\n",
    "b = 0.0\n",
    "\n",
    "# Definicja funkcji sigmoidalnej\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Definicja funkcji kosztu\n",
    "def compute_loss(X, y, W, b):\n",
    "    m = len(y)\n",
    "    p = sigmoid(np.dot(X, W) + b)\n",
    "    cost = - (y * np.log(p + epsilon) + (1 - y) * np.log(1 - p + epsilon))\n",
    "    return np.mean(cost)\n",
    "\n",
    "# Definicja pochodnej i obliczenia na macierzy\n",
    "def compute_derivative(X, Y, Y_hat):\n",
    "    m = X.shape[0]\n",
    "    dW = np.dot(X.T, (Y_hat - Y)) / m\n",
    "    db = np.sum(Y_hat - Y) / m\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb3246",
   "metadata": {},
   "source": [
    "## Inicjacja funkcji bezpo≈õrednio dot. regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b9efc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktualizacja wag\n",
    "def update_parameters(W, b, dW, db, learning_rate):\n",
    "    W -= learning_rate * dW\n",
    "    b -= learning_rate * db\n",
    "    return W, b\n",
    "\n",
    "# Funkcja predykcji\n",
    "def predict(X, W, b):\n",
    "    z = np.dot(X, W) + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "# Funkcja obliczania gradient√≥w\n",
    "def compute_gradients(X, Y, Y_hat):\n",
    "    m = X.shape[0]\n",
    "    dW = np.dot(X.T, (Y_hat - Y)) / m\n",
    "    db = np.sum(Y_hat - Y) / m\n",
    "    return dW, db\n",
    "\n",
    "# Funkcja trenowania modelu\n",
    "def train(X, Y, epochs=1000, learning_rate=0.01, tol=1e-6):\n",
    "    n_features = X.shape[1]\n",
    "    W = np.zeros(n_features)\n",
    "    b = 0.0\n",
    "    prev_loss = float('inf')\n",
    "\n",
    "    for i in range(epochs):\n",
    "        Y_hat = predict(X, W, b)\n",
    "        loss = compute_loss(X, Y, W, b)\n",
    "        dW, db = compute_gradients(X, Y, Y_hat)\n",
    "        W, b = update_parameters(W, b, dW, db, learning_rate)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch {i}, Loss: {loss:.4f}')\n",
    "        \n",
    "        if abs(prev_loss - loss) < tol:\n",
    "            print(f'Zbie≈ºno≈õƒá osiƒÖgniƒôta po {i} epokach (delta L < {tol})')\n",
    "            break\n",
    "        prev_loss = loss\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d2009",
   "metadata": {},
   "source": [
    "## Ocena modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd338143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931\n",
      "Epoch 50, Loss: 0.6206\n",
      "Epoch 100, Loss: 0.5694\n",
      "Epoch 150, Loss: 0.5323\n",
      "Epoch 200, Loss: 0.5048\n",
      "Epoch 250, Loss: 0.4839\n",
      "Epoch 300, Loss: 0.4675\n",
      "Epoch 350, Loss: 0.4545\n",
      "Epoch 400, Loss: 0.4439\n",
      "Epoch 450, Loss: 0.4352\n",
      "Epoch 500, Loss: 0.4279\n",
      "Epoch 550, Loss: 0.4217\n",
      "Epoch 600, Loss: 0.4164\n",
      "Epoch 650, Loss: 0.4119\n",
      "Epoch 700, Loss: 0.4079\n",
      "Epoch 750, Loss: 0.4044\n",
      "Epoch 800, Loss: 0.4013\n",
      "Epoch 850, Loss: 0.3985\n",
      "Epoch 900, Loss: 0.3961\n",
      "Epoch 950, Loss: 0.3939\n",
      "Epoch 1000, Loss: 0.3918\n",
      "Epoch 1050, Loss: 0.3900\n",
      "Epoch 1100, Loss: 0.3884\n",
      "Epoch 1150, Loss: 0.3868\n",
      "Epoch 1200, Loss: 0.3854\n",
      "Epoch 1250, Loss: 0.3841\n",
      "Epoch 1300, Loss: 0.3829\n",
      "Epoch 1350, Loss: 0.3818\n",
      "Epoch 1400, Loss: 0.3808\n",
      "Epoch 1450, Loss: 0.3798\n",
      "Epoch 1500, Loss: 0.3789\n",
      "Epoch 1550, Loss: 0.3781\n",
      "Epoch 1600, Loss: 0.3773\n",
      "Epoch 1650, Loss: 0.3766\n",
      "Epoch 1700, Loss: 0.3759\n",
      "Epoch 1750, Loss: 0.3752\n",
      "Epoch 1800, Loss: 0.3746\n",
      "Epoch 1850, Loss: 0.3740\n",
      "Epoch 1900, Loss: 0.3734\n",
      "Epoch 1950, Loss: 0.3729\n",
      "Zbie≈ºno≈õƒá osiƒÖgniƒôta po 1992 epokach (delta L < 1e-05)\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.88\n",
      "Recall: 0.9166666666666666\n",
      "F1-score: 0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "W, b = train(X_train, y_train, epochs=2000, learning_rate=0.005, tol=1e-5)\n",
    "\n",
    "y_pred = predict(X_test, W, b) > 0.5\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac21ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
